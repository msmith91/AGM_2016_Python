{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Exercises For All-GRAD Meetup \n",
    "\n",
    "#### Michael Smith,  May, 2016\n",
    "\n",
    "## Intro\n",
    "\n",
    "This workbook is intended as an interactive introduction to writing Python code.  My goal is to introduce some general concepts specific to working with arrays and datasets inherent to the Numpy and Pandas packages.  We'll do some basic data manipulation, aggregation to produce summary statistics, and then we'll run a regression and do some plotting.\n",
    "\n",
    "Remember: To run a cell, click within the cell and use Shift+Enter.  You can click within the cell, edit the code, and rerun to change the output.  You can always shutdown the notebook by selecting File->'Close and Halt'.\n",
    "\n",
    "Some cells will contain only a comment asking you to fill in the cell with corresponding code. Give these a try using what you've learned so far.  We'll go through the answers together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Syntax\n",
    "\n",
    "Python uses a syntax somewhat-similar to that you may have experienced in R or Matlab.  No semi-colons, no variable-type declarations needed, and indents for code blocking.  We can create variables of any kind by simply giving a name and equating them to a value (number, string) or an object (list, dictionary, array, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Numbers...\n",
    "\n",
    "x = 1\n",
    "y = 2\n",
    "z = x+y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Strings...\n",
    "\n",
    "x = 'abc'\n",
    "y = '123'\n",
    "z = x+y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lists...\n",
    "\n",
    "x = ['a','b',2]\n",
    "y = [3,10,'a']\n",
    "z = x+y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy (Sounds like Num Pie - from Num[ber] Py[thon]) provides a structure for working with arrays (a special kind of list).  It's the basic structure of many aspects of data analysis in Python.  Below are some basic aspects of the Numpy array.\n",
    "\n",
    "To load a package into your python session, use the syntax \"import ...\".  Python lets you name the package so that referencing it is simpler throughout your program.  To do this, add \"as ...\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command loads the package 'Numpy' at it's most stable release into our Python session and allows us to use it's various methods and attributes.  We name it 'np' for simplicity in writing code.\n",
    "\n",
    "For the documentation included in the package, you can put a ? in-front of specific methods like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank-1 Array\n",
    "\n",
    "The most basic of the Numpy Array structures - let's look at creating one and some basic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create the numpy array by using the array() function from the Numpy package (which we've named 'np')\n",
    "\n",
    "a = np.array([1,2,3,4])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get the first element of the array (Numpy Arrays are 0-indexed, meaning the first entry is in index 0)\n",
    "\n",
    "print(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get the first 2 elements of the array (The end of the range is not inclusive)\n",
    "\n",
    "print(a[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#An example of basic array arithmetic - Taking each element of a to the 2nd power\n",
    "\n",
    "print(a**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create a new array, b, which is a series of (4,5,6,7)\n",
    "\n",
    "b = ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fill in the brackets to print the last two elements of b\n",
    "\n",
    "print(b[####])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Rank Array\n",
    "The numpy array can be extended into any number of dimensions by creating arrays of arrays.  Below we initialize a new array from our two, .  We'll look at some indexing and summary statisics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lets combine our two 1D arrays together into a new 2-row, 4-column array\n",
    "\n",
    "c = np.array([a,b])\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The first index of a rank-2 array is a rank-1 array (array 'a' in this case)\n",
    "\n",
    "print(c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Indexing in genearl goes 'array[row(s),column(s)]' and ':' can be used to indicate ranges\n",
    "\n",
    "print(c[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get a 2D sub-matrix of the first two rows and first two columns\n",
    "\n",
    "print(c[0:2,0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Mean of the first column of c\n",
    "\n",
    "np.mean(c[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Median of the first row of c\n",
    "\n",
    "np.median(c[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fill in the parenthesis to use the np.std() method to get the standard deviation of the second row\n",
    "\n",
    "np.std(###)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "Pandas takes the Numpy Array and extends it's functionality to create data frames which are N-Dimensional arrays of M rows which also are given column names and row index values.  The Pandas package gives easy ways to work with this kind of structure called a dataframe as well as time series data.  We'll review the basic dataframe and some of it's functionality below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "?pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading In Data\n",
    "One of the great functions within the Pandas package is the ability to quickly and intuitively read in csv files without\n",
    "explicitly defining each variable type.  The data we'll look at is daily sales across 100 stores for one product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pandas read_csv function from the pandas package (which, remember, we're calling pd):\n",
    "\n",
    "test_data = pd.read_csv('daily_data_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe Attributes\n",
    "Pandas Dataframes have many inherent attributes that can be accessed by adding '.attribute' after the dataframe.  We'll look at some below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe Dimensions\n",
    "What does the dataframe look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get the shape (rows,columns) for our test_data\n",
    "\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#columns shows the names of all columns\n",
    "\n",
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We can get full set of summary statistics via the .describe() method\n"
    "\n"
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Head/Tail Views\n",
    "Like many other languages, we can quickly view the first and last rows of the dataframe with the .head and .tail attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#.head() will give the first 5 rows for all columns\n",
    "\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#.tail() will return the last 5 rows\n",
    "\n",
    "test_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe Slicing\n",
    "The 'ix' attribute allows you to slice the data frame in the same way as we used for the Numpy N-Dimensional Array.\n",
    "\n",
    "**One note - slice ranges now are inclusive (0:1 gets both the 0th element and the 1st element, whereas with numpy, it would\n",
    "  have only generated the 0th element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get the first 10 rows for all columns (rows 0-4 and all columns)\n",
    "\n",
    "test_data.ix[0:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe Statistics\n",
    "We get most of the same descriptive statistic attributes as numpy.  For example, .mean(), .std(), .corrcoef(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get the mean values for all numerical columns in the dataframe:\n",
    "\n",
    "test_data.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fill in the brackets to pull rows 20 - 25 of column index 2:\n",
    "\n",
    "test_data.ix[###]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fill in the ### with the attribute to find the standard deviation of all numerical columns in test_data:\n",
    "\n",
    "test_data.###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Dataframe Features\n",
    "\n",
    "Let's look at selecting columns, selecting subsets of data, creating new columns, sorting, creating pivot tables, and merging two data frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Selection and Filtering\n",
    "Instead of slicing by row and column index values, we can use more intuitive column names and conditions to select row/column combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Selecting just one column by label:\n",
    "\n",
    "test_data['Store'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Selecting multiple columns:\n",
    "\n",
    "test_data[['Store','Date']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Use the Date column to filter data on just Mondays:\n",
    "\n",
    "test_data[test_data['Weekday'] == 'Monday'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We can create a new column that dictates whether the day is a Sunday or not by using the where() method on a single column\n",
    "\n",
    "test_data['Sunday'] = np.where(test_data['Weekday'] == 'Sunday',1,0)\n",
    "test_data.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fill in the brakets to use the Store column to filter for just Store 20157\n",
    "\n",
    "test_data[###].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fill in the ### to complete the conditional selection of data where column Date = '03/01/2014' and find the column averages.\n",
    "\n",
    "test_data[###].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting\n",
    "Pandas dataframes have a .sort_values() method allows you to sort by multiple columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Sort test_data by Store, then Units\n",
    "\n",
    "test_data.sort_values(['Store','Units']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pivot Tables\n",
    "We can aggregate data in a Pivot Table format across classification variables with the dataframe method .pivot_table().  Pivot Tables have the helpful property that the output table is in the format of 'index:value'.  We'll see how this comes in handy when we merge two of them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Here we aggregate the Units variable in our dataframe, test_data.  We do this at the Store level\n",
    "\n",
    "store_avg = pd.pivot_table(test_data, values='Units', index='Store', aggfunc='mean')\n",
    "store_avg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fill in the blanks to create a sum of promoted days across the Store variable\n",
    "\n",
    "store_promo = pd.pivot_table(###)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fill in the blanks to create a 'Store Size' = Sum of Units by Store\n",
    "\n",
    "store_size = pd.pivot_table(###)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fill in the blanks to create a pivot table using a conditional row selection to find avg sales by store where Weekday = 'Saturday'.\n",
    "\n",
    "avg_sat_sales = pd.pivot_table(test_data[###],values='###',index='###',aggfunc='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joining Data\n",
    "Pandas has two helpful methods for joining dataframes - merge and concat.\n",
    "\n",
    "Merge is useful when you are combining two dataframes with inconsistent indecies. It allows you two choose which columns of the dataframe should be used to do the join. If both dataframes use the same type of index and that's what you want to use to do the join, then the concat method is easy to use with fewer necessary inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We used the same Index variable (Store) in all three pivot tables created above.  Thus, we can use concat to join them into one.\n",
    "\n",
    "store_agg_data = pd.concat([store_avg, store_promo, store_size,avg_sat_sales],axis=1)\n",
    "store_agg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We aggregated by Units in three of the pivot tables, so let's rename the items in the .columns attribute\n",
    "\n",
    "store_agg_data.columns = ['avg_daily_sales','sum_promo_days','store_size','avg_sat_sales']\n",
    "store_agg_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "Now that we have a couple of datasets to work with, we can do some basic analysis using some statistics, plots, and regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Using our merged dataset, store_agg_data and the .corr() correlation attribute, fill in the ## to look at correlation between\n",
    "#avg_promo_days, store_size, and avg_sat_sales\n",
    "\n",
    "store_agg_data[[###]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, we see a very strong relationship between how a store performs on a saturday and how it performs overall.\n",
    "\n",
    "What if we want to plot this relationship in a scatter plot?  Lucky for us, Pandas dataframes have plotting methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First some Notebook magic to make the plots render inline with the cells.\n",
    "%matplotlib inline\n",
    "\n",
    "#Next, use the Pandas .plot.scatter() with a selection of x and y variables\n",
    "\n",
    "store_agg_data.plot.scatter('avg_sat_sales','store_size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, suppose we're curious about the promotional lift for this product across this set of stores.  There is a package called statsmodels that contains many regresssion and other statistical methods that work well with Pandas dataframes and make modeling  pretty intuitive.  We'll use the statsmodel's OLS package below to model daily units as a function of the day of the week and whether it's a promoted day or not.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#first, import ols formula package as 'sm'\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "#the first step is creating the model 'object'. \n",
    "model_results = sm.ols(formula='Units ~ Promo + Weekday',data=test_data).fit()\n",
    "\n",
    "#This object will then have attributes and methods such as the .summary() which gives the overview of the model fit\n",
    "model_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
